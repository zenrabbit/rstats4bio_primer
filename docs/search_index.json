[["index.html", "A primer for biostatistics in R Chapter 1 Introduction", " A primer for biostatistics in R cjlortie Chapter 1 Introduction Welcome to a primer for biostatistics in R. Mathematical! Adventure time! Well, the mathematical part is up to you, but this is an adventure. This set of learning materials is a guide developed to support you in better developing critical thinking using statistics. Critical thinking very generally is a mode of thinking that is self-directed and evidence based (Facionie 2017). Statistical thinking is thus an ideal opportunity and partner in honing literacy adventure skills in this domain. Enhancing clarity, accuracy, precision, relevance, depth, breadth, significance, logic and fairness - all key criteria of critical thinking - with data or evidence both quantitative and qualitative is a profound tool as a scientist and citizen. It should be fundamental to statistics. Hence, the primary goal of this set of materials is to engender statistical thinking that embodies these principles and explores these criteria using data. The open and free resources associated with learning statistics is nearly infinite online particularly in R. The programming language R is a free, open source programming environment ideal for statistics. There are other similar alternatives, but here R is used to support and scaffold critical thinking and statistical literacy because a significant component of many biologists use R including ecologists (Lai et al. 2019). Importantly, it provides a simple and clear mechanism to document, annotate, tidy up, write down, and literally show your work - like in math class. This benefits you. You see your ideas written down and can explore logic, fairness, and all the criteria listed above. It also enables you to repeat, replicate, and share your work. Course outline If you are electing to engage with this learning opportunity formally for BIOL5081 at York University, here is the official course outline. Learning outcomes Build a tidy, logical data model for a graduate-level dataset. Develop a reproducible data and statistical workflow. Design and complete intermediate-level data visualizations appropriate for a graduate-level tidy dataset. Identify a range of suitable univariate or multivariate statistical approaches that can be applied to any dataset. Interpret statistical output to quantify statistical model performance. Complete fundamental exploratory data analysis on a representative dataset. Appreciate the strengths and limitations of open science, data science, and evidence-based collaboration models. Structure Read a book. The new statistics with R. An introduction for biologists (Hector 2017). Write a book review. Ten simple rules for writing statistical book reviews (Christopher J. Lortie 2019) suggests a critical thinking framework to adopt for this process. Learn-by-doing here. Do a hackathon. Do a hackathon as a test and submit for grading &amp; review. Rationale Some learn best by reading. Some learn best by doing. We can all benefit from both approaches to refining our critical thinking through statistics. Two summative (i.e. graded outcomes) include the book review and the test. Schedule Slide decks are optional. The decks simply highlight some of the connections between the criteria for critical thinking and statistical heuristics. week adventure slide deck 1 Tidy data in R whyR 2 Literate statistical coding and Data science wrangleR 3 Statistics for ecology and evolution I (CH4 in text) contemporary viz 4 Statistics for ecology and evolution II (CH10 and 11 in text) EDAR 5 Book review due and hackathon efficient stats 6 Test when to publish data &amp; code Instructions Read the text at your own pace. At least hit the key chapters CH4, 10 &amp; 11 to write the review and submit your insights by the fifth week of work (if you choose to do 1-2 tasks per week as suggested in the schedule). If you are taking BIOL5081, please see official course outline and submit all work to turnitin.com as PDF only (even for the R work - knit to pdf). Each week, read, discuss if you elect to work synchronously, and try the challenge provided. The final two weeks, that hackathon is a warm up to the test. Grab the dataset, apply your critical thinking skills, code and show your work, and capture code and outputs as PDF. The hackathon is a stepping stone, formative process for to check if you are ready to think on your feet, write code, and apply biostatistical thinking to a challenge. The test is the exact same approach but summative, i.e. you submit for review and grading to a peer or instructor like me. Citation License This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Tidy data in R Tidiness is next to naturalness. We are wired up to see patterns and organize. Put that tendency to good work in data and statistical critical thinking. Learning outcomes Consider data structures such as long versus wide. Read in a dataset to the R environment. Do a t-test. Critical thinking Tidy data thinking was pioneered in the R world (Wickham 2014). This philosophy to first considering the basic format of your data is transformational and profound. It beautifully connects to logic. Better yet, it sets you up for easier stats and plots in many environments including R. There is an excellent chapter on this topic in the free, open text R for Data Science. Adventure time Very simple life data to explore some ideas about meditation, steps, resting heart rate and the importance of instrument variation. Data are here. Explore the t-test in R for this adventure. Is the number of steps or sleep different from 0? Do the means estimated from a watch versus simple Fitbit tracker vary for simple measures? Did 0 versus 12 mins of meditation per day influence a relevant measure? library(tidyverse) simple_life &lt;- read_csv(url(&quot;https://ndownloader.figshare.com/files/28920855&quot;)) simple_life ## # A tibble: 9 x 7 ## simple_date steps_fitbit sleep_fitbit hr steps_watch sleep_watch ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-06-02 20913 429 54 25197 314 ## 2 2021-06-03 6904 447 53 13042 302 ## 3 2021-06-04 19548 449 56 23285 413 ## 4 2021-06-05 19311 423 56 25832 355 ## 5 2021-06-06 26159 435 58 29533 385 ## 6 2021-06-07 21618 358 56 27796 240 ## 7 2021-06-08 20890 492 53 24360 434 ## 8 2021-06-09 12008 541 53 14517 399 ## 9 2021-06-10 18058 436 57 22392 403 ## # … with 1 more variable: meditation_mins &lt;dbl&gt; Reflection questions What can a t-test do? Can you imagine other functions for a t-test in the context of your work and life? What are the limitations of a t-test? Is the data structure wide, long, and how can you consider tidying this evidence? Are there variables that represent the same concept? "],["coding.html", "Chapter 2 Literate coding", " Chapter 2 Literate coding Your code is a story too. Use your code and annotation of decisions (en)coded in your data manipulations, calculations, models, and plots to communicate clarity, logic, relevance, and depth. This story is not just for your collaborators - it is for you. Writing down your ideas and work down makes it more clear. It also reminds you later, even a week later, why you elected to make a particular decision in your workflow. Tidy data and tidy thinking make for better science. Learning outcomes Practice writing code and using annotation. Consolidate your understanding of tidy data and critical thinking statistically. Do an ANOVA. Critical thinking Tidy data make your life easier. Data structures should match intuition and common sense. Data should have logical structure. Rows are are observations, columns are variables. Tidy data also increase the viability that others can use your data, do better science, reuse science, and help you and your ideas survive and thrive. Literate coding (Knuth 1992) should capture a workflow that includes the wrangling you did to get your data ready. Literate code should be able to read by a human AND a machine. If data are already very clean in a spreadsheet, they can easily become a literate, logical dataframe. Nonetheless, you should still use annotation within the introductory code to explain the meta-data of your data to some extent and what you did pre-R to get it tidy. The philosophy here is very similar to the data viz lesson forthcoming that promotes critical thinking statistically through documented and described steps that are replicable and clear. Adventure time Many years ago in a galaxy far, far away, a student sowed seeds in the desert at different densities for their PhD research. Here are the data, and here is the publication too (Christopher J. Lortie and Turkington 2002). This student was not strong in the force, but it was a good adventure in beginning to understand the relative importance of significance biologically and statistically by exploring critical thinking. For your adventure, test whether a set of groups differ from one another. For instance, test whether transects, or years, or even the density of seeds planted differs in an outcome measure such as mean plant size. library(tidyverse) density &lt;- read_csv(url(&quot;https://ndownloader.figshare.com/files/28934310&quot;)) density ## # A tibble: 152 x 6 ## year transect seed_density_pe… final_plant_den… survivorship mean_plant_size ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1998 1 0.0625 41 0.461 0.554 ## 2 1998 1 0.0625 47 0.712 0.356 ## 3 1998 1 0.0625 60 0.698 0.301 ## 4 1998 1 0.25 31 0.525 0.808 ## 5 1998 1 0.25 50 0.505 0.212 ## 6 1998 1 0.25 58 0.563 0.148 ## 7 1998 1 1 30 0.273 0.578 ## 8 1998 1 1 42 0.243 1.28 ## 9 1998 1 1 73 0.619 0.719 ## 10 1998 1 2 46 0.263 0.652 ## # … with 142 more rows Reflection questions What is the difference between a t-test and an ANOVA? What is the difference between an ANOVA and GLM? What are some of the ways that these simple data can be further analyzed? When you explored annotation and describing your decisions and workflow for these data adventure, was it logical and clear to you if you ignored the R code? "],["eebI.html", "Chapter 3 Stats used in eeb I", " Chapter 3 Stats used in eeb I Many approaches and critical thinking heuristics in ecology &amp; evolutionary biology (eeb) are relevant to other disciplines. Learning outcomes Develop your data viz skills. Hone your critical thinking statistically by iterative plotting-modeling a dataset. Do a regression analysis. Critical thinking Clean simple graphics are powerful tools in statistics (and in scientific communication). Tufte (Tufte 2006) and others have shaped data scientists and statisticians in developing more libraries, new standards, and assumptions associated with graphical representations of data. Data viz must highlight the differences, show underlying data structures, and provide insights into the specific research project. R is infinitely customizable in all these respects. There are at least two major current paradigms (there are more these are the two dominant idea sets). Base R plots are simple, relatively flexible, and very easy. However, their grammar, i.e their rules of coding are not modern. Ggplot and related libraries invoke a new, formal grammar of graphics (Leland 2005) that is more logical, more flexible, but divergent from base R code. It is worth the time to understand the differences and know when to use each. Evolution of plotting in statistics using R in particular went from base-R then onto lattice then to the ggvis universe with the most recent library being ggplot (Wickham 2016). Base-R is certainly useful in some contexts as is the lattice and lattice extra library. However, ggplot now encompasses all these capacities with a much simpler set of grammar (i.e. rules and order). Nonetheless, you should be able to read base-R code for plots and be able to do some as well. The philosophy or grammar of modern graphics is well articulated and includes the following key principles. The grammar of graphics layers primacy of ideas (simple first, then more complex) i.e. you build up your plots data are mapped to aesthetic attributes and geometric objects data first then statistics even in plots (Wickham 2010). This directly supports critical thinking statistically because it promotes depth (literally), precision, and also accuracy in the decisions you make to show your evidence. Adventure time Here are a deeper set of quanitified life data. Explore whether movement predicts total sleep or its efficiency. Plot out some patterns first, then, do a regression. library(tidyverse) life &lt;- read_csv(url(&quot;https://ndownloader.figshare.com/files/28920729&quot;)) life ## # A tibble: 4,561 x 7 ## simple_date year steps mins_asleep efficiency lagged_sleep lagged_efficiency ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2011-01-25 2011 13900 481 96 504 99 ## 2 2011-01-26 2011 19229 478 96 481 96 ## 3 2011-01-27 2011 13103 474 96 478 96 ## 4 2011-01-28 2011 7374 491 96 474 96 ## 5 2011-01-29 2011 19132 436 96 491 96 ## 6 2011-01-30 2011 17157 447 98 436 96 ## 7 2011-01-31 2011 19759 456 99 447 98 ## 8 2011-02-01 2011 18157 455 98 456 99 ## 9 2011-02-02 2011 8768 465 97 455 98 ## 10 2011-02-03 2011 9150 411 98 465 97 ## # … with 4,551 more rows Reflection questions When do you use regression versus correlation? How could you incorporate time into your plots or statistical models? Did the visualization highlight some of the criteria associated with critical thinking statistically more than others? "],["eebII.html", "Chapter 4 Stats used in eeb II", " Chapter 4 Stats used in eeb II "],["hackathon.html", "Chapter 5 Hackathon", " Chapter 5 Hackathon "],["test.html", "Chapter 6 Test", " Chapter 6 Test "],["references.html", "References", " References "]]
